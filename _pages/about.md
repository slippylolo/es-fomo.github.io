---
layout: about
title: üè° workshop
permalink: /
subtitle: <i>Workshop at the International Conference on Machine Learning (ICML) 2023.</i>
---

![Banner](assets/img/banner.png){:width="512" .center-image}
*Code it, run it, crash it--restart it.*
{: style="color:gray; font-size: 80%; text-align: center;"}

## üî• the gist
* **what?** A workshop to bring together **interdisciplinary experts** working on the emerging research questions and challenges associated with **foundation model training and inference**.
* **when & where?**
  * **Attend the workshop**, **`29th of July 2023`**, **[Ballroom A (floor L4)](https://map.concept3d.com/?id=1107#!m/242756)**, in Honolulu, Hawaii‚Äîor join us virtually through the [official ICML website](https://icml.cc);
  * Check-out the **accepted papers** on **[OpenReview](https://openreview.net/group?id=ICML.cc/2023/Workshop/ES-FoMO)**;
  * Party with us at the **happy hour sponsored by [Together](https://together.ai)**, RSVP on [Partiful](https://partiful.com/e/h4AW66So2V7DOysQxNkX) to get a ticket!
* **questions?** Contact us at `esfomo.workshop@gmail.com`.
  
![Banner](assets/img/together-small.png){:width="128" .center-image}
*Awards and post-workshop happy hour sponsored by [Together](https://together.ai).*
{: style="color:gray; font-size: 80%; text-align: center;"}

<br>

## üìÜ the plan
*All times HST, UTC-10. Find us in [Ballroom A (floor L4)](https://map.concept3d.com/?id=1107#!m/242756) of the convention center.*

|         | Topic                                                                                                                                     | Speaker                                                         |
| ------- | ----------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------- |
| 8:55am  | *Opening remarks*                                                                                                                         |                                                                 |
| 9:00am  | üî• **Session I: Large-Scale Distributed Pretraining**                                                                                     |                                                                 |
|         | Using Megatron to Train Large Language Models                                                                                             | Deepak Narayanan <br> *(Microsoft Research)*                    |
|         | Distributed Systems for Decentralized AI                                                                                                  | Ce Zhang <br> *(ETH, Together)*                                 |
|         | Training Large Language Models on Cerebras Wafer-Scale Clusters AI                                                                                                  | Natalia Vassilieva <br> *(Cerebras)*                                 |
| 10:10am | *Coffee break*                                                                                                                            |                                                                 |
| 10:25am | üé§ **Contributed Talk 1**                                                                                                                 |                                                                 |
|         | SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores                                                                | Yi Wu   <br> *(Tsinghua University, Shanghai Qi Zhi Institute)* |
| 10:40am | üé§ **Contributed Talk 2**                                                                                                                 |                                                                 |
|         | Finetuning Language Models with Just Forward Passes                                                                                       | Sadhika Malladi <br> *(Princeton University)*                   |
| 10:55am | üöÄ **Session II: Efficient Inference**                                                                                                    |                                                                 |
|         | The Case for 4-bit Inference                                                                                                              | Tim Dettmers <br> *(University of Washington)*                  |
|         | Efficienly Scaling Transformer Inference                                                                                                  | Aakanksha Chowdhery <br> *(Google Research)*                    |
| 11:55am | üé§ **Contributed Talk 3**                                                                                                                 |                                                                 |
|         | Memory-Efficient Selective Finetuning                                                                                                     | Antoine Simoulin <br> *(Meta)*                                  |
| 12:10pm | *Lunch break*                                                                                                                             |                                                                 |
| 1:00pm  | üßë‚Äçüéì **Poster Session**                                                                                                                  |                                                                 |
| 2:00pm  | üé§ **Contributed Talk 4**                                                                                                                 |                                                                 |
|         | On IO-Efficient Attention Mechanisms: Context-Aware Bifurcated Attention and the Generalized Multi-Group Attention                        | Ben Athiwarathkum<br> *(AWS AI Labs)*                           |
|         |                                                                                                                                           |                                                                 |
| 2:15pm  | üí¨ **Panel: Large Language Models Tooling Across Industry and Academia**                                                                  |                                                                 |
|         | Anna Goldie *(Anthropic)*, Rishi Bommasani *(Stanford University)*, Susan Zhang *(Meta)*, Emily Webber *(AWS)*, James Bradbury *(Google)* |                                                                 |
|         | *Moderated by Abhi Venigalla (Mosaic.ML), Dylan Patel (SemiAnalysis).*                                                                    |                                                                 |
| 3:15pm  | *Coffee break*                                                                                                                            |                                                                 |
| 3:30pm  | üé§ **Contributed Talk 5**                                                                                                                 |                                                                 |
|         | Fast Causal Attention with Dynamic Sparsity                                                                                               | Daniele Paliotta <br> *(University of Geneva)*                  |
|         |                                                                                                                                           |                                                                 |
| 3:45pm  | ‚öôÔ∏è **Session III: Deep Optimization**                                                                                                     |                                                                 |
|         | PyTorch 2.x: Faster, More Pythonic, and as Dynamic as Ever                                                                                | Natalia Gimelshein <br> *(OpenAI)*                              |
|         | High-Performance Kernel Programming with Triton                                                                                           | Philippe Tillet <br> *(OpenAI)*                                 |
| 4:45pm  | üèÖ **Awards**                                                                                                                             |                                                                 |
| 6:00pm  | üéâ **Post-workshop happy hour**                                                                                                           | *sponsored by Together*                                         |
|         | *RSVP on [Partiful](https://partiful.com/e/h4AW66So2V7DOysQxNkX) to get a ticket!*                                                          |                                                                 |

<br>

## ü¶æ the pitch

As models increase in size and training budget, they not only systematically improve in upstream quality, but also exhibit novel emergent capabilities. This increase in scale raises proportionate difficulties for practitioners: foundation model training and inference lie at a unique interdisciplinary crossroad, combining open problems in algorithms, system design, and software engineering. 

Machine learning practitioners are key stakeholders here: on the one hand, researchers may contribute algorithmic insights and novel methods to improving training and inference of large models; on the other hand, novel research findings may be best demonstrated at scale‚Äîwhich may require training models as efficiently as possible to make the best use of available resources. 

The goal of this workshop is to **bring together interdisciplinary experts working on the emerging research questions and challenges associated with foundation model training and inference**. We welcome submissions around training and inference systems/algorithms for foundation models, focusing on scaling-up or on reducing compute, time, memory, bandwidth, and energy requirements. Notably, we encourage submissions concerning the entire spectrum of foundation models: from BERT-sized Transformers, to large models with 100B+ parameters. Topics include but are not limited to (see our [**üìù call for papers**](/call/) for details): 
* **Training and inference systems**, either distributed at large scale or in resource-constrained scenarios;
* **Algorithms for improved training and inference efficiency**;
* **Systems for foundation models**, such as novel programming languages or compilers. 

<br>

## üßë‚Äçüè´ the speakers

<div class="projects">
  {%- assign sorted_projects = site.projects | sort: "importance" | where: "category", "speaker" -%}
  <!-- Generate cards for each project -->
  {% if page.horizontal -%}
  <div class="container">
    <div class="row row-cols-2">
    {%- for project in sorted_projects -%}
      {% include projects_horizontal.html %}
    {%- endfor %}
    </div>
  </div>
  {%- else -%}
  <div class="grid">
    {%- for project in sorted_projects -%}
      {% include projects.html %}
    {%- endfor %}
  </div>
  {%- endif -%}
</div>

<br>

## üí¨ the panelists (& moderators)

<div class="projects">
  {%- assign sorted_projects = site.projects | sort: "importance" | where: "category", "panelist" -%}
  <!-- Generate cards for each project -->
  {% if page.horizontal -%}
  <div class="container">
    <div class="row row-cols-2">
    {%- for project in sorted_projects -%}
      {% include projects_horizontal.html %}
    {%- endfor %}
    </div>
  </div>
  {%- else -%}
  <div class="grid">
    {%- for project in sorted_projects -%}
      {% include projects.html %}
    {%- endfor %}
  </div>
  {%- endif -%}
</div>

<br>

## üòé the organizers

<div class="projects">
  {%- assign sorted_projects = site.projects | sort: "importance" | where: "category", "organizer" -%}
  <!-- Generate cards for each project -->
  {% if page.horizontal -%}
  <div class="container">
    <div class="row row-cols-2">
    {%- for project in sorted_projects -%}
      {% include projects_horizontal.html %}
    {%- endfor %}
    </div>
  </div>
  {%- else -%}
  <div class="grid">
    {%- for project in sorted_projects -%}
      {% include projects.html %}
    {%- endfor %}
  </div>
  {%- endif -%}
</div>


<br>

## üòç the sponsors 

<div class="projects">
  {%- assign sorted_projects = site.projects | sort: "importance" | where: "category", "sponsor" -%}
  <!-- Generate cards for each project -->
  {% if page.horizontal -%}
  <div class="container">
    <div class="row row-cols-2">
    {%- for project in sorted_projects -%}
      {% include projects_horizontal.html %}
    {%- endfor %}
    </div>
  </div>
  {%- else -%}
  <div class="grid">
    {%- for project in sorted_projects -%}
      {% include projects.html %}
    {%- endfor %}
  </div>
  {%- endif -%}
</div>
